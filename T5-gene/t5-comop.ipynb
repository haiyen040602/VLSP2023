{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"03e73c13fa3f4ac591481dcb0680e0ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb0a961161034c02bf99312400a31bcb","IPY_MODEL_1da887039ccb4b64ab6c6ab96afe072d","IPY_MODEL_5da623c4ebd34b63a7ed46cb5e905ec9"],"layout":"IPY_MODEL_503cbaafd5d44836bb4460576bbc7b3d"}},"fb0a961161034c02bf99312400a31bcb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d38da91adcc5442eb415eaac6257f2aa","placeholder":"​","style":"IPY_MODEL_5dfa695786d544dfbc436d4c9c3c72a9","value":"tokenizer_config.json: 100%"}},"1da887039ccb4b64ab6c6ab96afe072d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a534d7bbfb07460bbdff9aec41240b94","max":2197,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b931a645b6a456ead2c298294dc68a2","value":2197}},"5da623c4ebd34b63a7ed46cb5e905ec9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_942a37bf3a9a4b9ea64ea632bf323399","placeholder":"​","style":"IPY_MODEL_283fa71cd39c4fc79ae04c055a6d7e8e","value":" 2.20k/2.20k [00:00&lt;00:00, 125kB/s]"}},"503cbaafd5d44836bb4460576bbc7b3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d38da91adcc5442eb415eaac6257f2aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dfa695786d544dfbc436d4c9c3c72a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a534d7bbfb07460bbdff9aec41240b94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b931a645b6a456ead2c298294dc68a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"942a37bf3a9a4b9ea64ea632bf323399":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"283fa71cd39c4fc79ae04c055a6d7e8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf0405f9b5b04a9f91907696bd1011e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3157036636544c2ea8a015ad0c45b0d8","IPY_MODEL_8cee76ca292c46d28ab84771fdba98bd","IPY_MODEL_d864ecad4efd4c0297593b06c6aa9abb"],"layout":"IPY_MODEL_486af23cbb3448d9b643551a1828446c"}},"3157036636544c2ea8a015ad0c45b0d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28b8fae7b94a47f4bbbcc4ae40e14a73","placeholder":"​","style":"IPY_MODEL_7aab991daf2c46c1a2a28decbff4e497","value":"spiece.model: 100%"}},"8cee76ca292c46d28ab84771fdba98bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_800572c3c1334f5d9bf36b6d1afac053","max":820370,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f374fdcca2a3475babd18a5287f383a5","value":820370}},"d864ecad4efd4c0297593b06c6aa9abb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0007f1138fae42ebb81d25c0ecb64aa6","placeholder":"​","style":"IPY_MODEL_a4103aaf2388411cba02d21e880b0961","value":" 820k/820k [00:00&lt;00:00, 6.28MB/s]"}},"486af23cbb3448d9b643551a1828446c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28b8fae7b94a47f4bbbcc4ae40e14a73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7aab991daf2c46c1a2a28decbff4e497":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"800572c3c1334f5d9bf36b6d1afac053":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f374fdcca2a3475babd18a5287f383a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0007f1138fae42ebb81d25c0ecb64aa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4103aaf2388411cba02d21e880b0961":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bf116ab37094fd79dcbacef395e1f08":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd27af606ad44acd9340cc42f50933f3","IPY_MODEL_5a403ed02a6c494098a9faa8d590b069","IPY_MODEL_5a14460af2634a15aff34400261bb47f"],"layout":"IPY_MODEL_80c55452f67847fbad36ac6683973df1"}},"bd27af606ad44acd9340cc42f50933f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3401569c285c4d97888fb875eea03d32","placeholder":"​","style":"IPY_MODEL_6358ca4c8b7448338e993815058059f4","value":"tokenizer.json: 100%"}},"5a403ed02a6c494098a9faa8d590b069":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1a7a89e93864ab6b6b7507bd95172fd","max":2399296,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c32162cac65b42958d1e59ae0ef48ce4","value":2399296}},"5a14460af2634a15aff34400261bb47f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c58a852023a6421da2dd8ddf4a05ff92","placeholder":"​","style":"IPY_MODEL_3aefda0024fc4c20a9e8b94966d5cfdf","value":" 2.40M/2.40M [00:00&lt;00:00, 12.9MB/s]"}},"80c55452f67847fbad36ac6683973df1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3401569c285c4d97888fb875eea03d32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6358ca4c8b7448338e993815058059f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1a7a89e93864ab6b6b7507bd95172fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c32162cac65b42958d1e59ae0ef48ce4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c58a852023a6421da2dd8ddf4a05ff92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3aefda0024fc4c20a9e8b94966d5cfdf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba076e57303042b29081bded561bea15":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19ad09f1bc884d46a9e65a0f5be8c933","IPY_MODEL_3109b3975f024ebd9105190af175a895","IPY_MODEL_c85ede0d001643678ff3fc34b69a4c21"],"layout":"IPY_MODEL_45220ee5a4644998bde636eb704c5912"}},"19ad09f1bc884d46a9e65a0f5be8c933":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da38524afff4443e8c5ee55af8e1d678","placeholder":"​","style":"IPY_MODEL_10994e524935429fa61a8815c7876e21","value":"special_tokens_map.json: 100%"}},"3109b3975f024ebd9105190af175a895":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c0eaab409e041b28ad251ac43f40c29","max":2117,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cc9b35dfa5842af91c6d62811c220c5","value":2117}},"c85ede0d001643678ff3fc34b69a4c21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85c02689ea96428995c02e720aa673d4","placeholder":"​","style":"IPY_MODEL_774ede8b054f4b1db77ee32622192879","value":" 2.12k/2.12k [00:00&lt;00:00, 83.9kB/s]"}},"45220ee5a4644998bde636eb704c5912":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da38524afff4443e8c5ee55af8e1d678":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10994e524935429fa61a8815c7876e21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c0eaab409e041b28ad251ac43f40c29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cc9b35dfa5842af91c6d62811c220c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85c02689ea96428995c02e720aa673d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"774ede8b054f4b1db77ee32622192879":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01c6d2ae0f2c44da9aac0014cbffa57b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb7d8c832f054f6e8a2db91bcaa7f35d","IPY_MODEL_21e263700f774a07a56647e88e466ba6","IPY_MODEL_2b24ad66b3594f15a67e967c6d8d516c"],"layout":"IPY_MODEL_d2d6d385385e4bbc81de1cf1087435f7"}},"bb7d8c832f054f6e8a2db91bcaa7f35d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c31b5084d7a40e6a596fe835e560187","placeholder":"​","style":"IPY_MODEL_fd535065b15e4316b659666bc4e086c4","value":"config.json: 100%"}},"21e263700f774a07a56647e88e466ba6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_865a329e364f463b9102672dc817eaa4","max":702,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1cd7a9fb0b2f4ba9a4ed9724d7d6b270","value":702}},"2b24ad66b3594f15a67e967c6d8d516c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6b3b6ae35c8401db983538ef70c4109","placeholder":"​","style":"IPY_MODEL_f59748b298ec4d948e8e11e91e3626f6","value":" 702/702 [00:00&lt;00:00, 49.4kB/s]"}},"d2d6d385385e4bbc81de1cf1087435f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c31b5084d7a40e6a596fe835e560187":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd535065b15e4316b659666bc4e086c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"865a329e364f463b9102672dc817eaa4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cd7a9fb0b2f4ba9a4ed9724d7d6b270":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6b3b6ae35c8401db983538ef70c4109":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f59748b298ec4d948e8e11e91e3626f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ecba3a4c7ce4e83ba8fbb0840dee5be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7213b1e518a14181aa1db3da597baa75","IPY_MODEL_747573005a1f4ee0b8175c7d40e5be73","IPY_MODEL_929fe194cc2949faa8d0675f0d60114d"],"layout":"IPY_MODEL_a7f40b0b557b4bc5aba940985af0b569"}},"7213b1e518a14181aa1db3da597baa75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43b1fd4d32b04d659736da3f740b4629","placeholder":"​","style":"IPY_MODEL_c1543a19d4f840e1a6164f34e1724883","value":"pytorch_model.bin: 100%"}},"747573005a1f4ee0b8175c7d40e5be73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15e89627504a4f108b123d80c57d2b48","max":903886847,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b673b71eb31c4fffa6a1a0c97fa21eb2","value":903886847}},"929fe194cc2949faa8d0675f0d60114d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_828b2024bb95402788287922ff6aa35b","placeholder":"​","style":"IPY_MODEL_2c7e172e351b4061a7ba290ed1ebc629","value":" 904M/904M [00:07&lt;00:00, 122MB/s]"}},"a7f40b0b557b4bc5aba940985af0b569":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43b1fd4d32b04d659736da3f740b4629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1543a19d4f840e1a6164f34e1724883":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15e89627504a4f108b123d80c57d2b48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b673b71eb31c4fffa6a1a0c97fa21eb2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"828b2024bb95402788287922ff6aa35b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c7e172e351b4061a7ba290ed1ebc629":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7037394,"sourceType":"datasetVersion","datasetId":4048764},{"sourceId":7047650,"sourceType":"datasetVersion","datasetId":4055540},{"sourceId":7055088,"sourceType":"datasetVersion","datasetId":4060702},{"sourceId":7058872,"sourceType":"datasetVersion","datasetId":4063528},{"sourceId":7062387,"sourceType":"datasetVersion","datasetId":4065944}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup\n\n\n\n","metadata":{"id":"iz3TBhE3BRyO"}},{"cell_type":"code","source":"# !pip install transformers -q\n# !pip install datasets -q\n# !pip install rouge -q\n# !pip install torch -q\n# !pip install tqdm -q","metadata":{"id":"Pb_0YnnmJh4i","outputId":"949d1d56-8d63-4d76-a550-dbb736cbb87e","execution":{"iopub.status.busy":"2023-11-27T21:50:15.407727Z","iopub.execute_input":"2023-11-27T21:50:15.408533Z","iopub.status.idle":"2023-11-27T21:50:15.413582Z","shell.execute_reply.started":"2023-11-27T21:50:15.408482Z","shell.execute_reply":"2023-11-27T21:50:15.412609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport os\nimport string\nimport operator\nimport random\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AdamW\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nfrom transformers import get_linear_schedule_with_warmup\nfrom tqdm import tqdm, trange\n\nseed = 42\ntorch.cuda.empty_cache()\ndevice = torch.device('cuda')","metadata":{"id":"XfoETcAH_qbZ","execution":{"iopub.status.busy":"2023-12-10T11:39:38.826925Z","iopub.execute_input":"2023-12-10T11:39:38.827195Z","iopub.status.idle":"2023-12-10T11:39:44.269133Z","shell.execute_reply.started":"2023-12-10T11:39:38.827169Z","shell.execute_reply":"2023-12-10T11:39:44.268353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Module Untils","metadata":{"id":"1EVJbMPvBbw-"}},{"cell_type":"code","source":"n_gpu = '0'\ngradient_accumulation_steps = 1\nlr = 2e-4\nadam_epsilon = 1e-8\nweight_decay = 0.0\nnum_warmup_steps= 0.0\nnum_train_epochs = 20\nsave_model = True\nsave_last_k = 1\nsave_last = True\ntrain_batch_size = 8\neval_batch_size = 128\nmodel_checkpoint = 'VietAI/vit5-base' #'google/mt5-base'\nmax_seq_length = 256\nelem_dict = [\"subject\", \"object\", \"aspect\", \"predicate\", \"label\"]\ndata_dir = \"/kaggle/input//t5-data-new/\"\n\nworking_dir = \"/kaggle/working\"\nresult_dir = f\"{working_dir}/result/model\"\ninference_dir = f\"{working_dir}/result/inference\"\n\nif not os.path.exists(result_dir):\n    os.makedirs(result_dir)\nif not os.path.exists(inference_dir):\n    os.makedirs(inference_dir)","metadata":{"id":"4FJt841DAJzv","execution":{"iopub.status.busy":"2023-12-10T11:39:44.270801Z","iopub.execute_input":"2023-12-10T11:39:44.271296Z","iopub.status.idle":"2023-12-10T11:39:44.279276Z","shell.execute_reply.started":"2023-12-10T11:39:44.271263Z","shell.execute_reply":"2023-12-10T11:39:44.277847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data utils","metadata":{"id":"P5EmFn0_ByF2"}},{"cell_type":"code","source":"import re\n\ndef read_data_file(data_path):\n  with open(data_path, 'r', encoding='UTF-8') as fp:\n      sents, labels = [], []\n      for line in fp:\n          # print(line)\n          line = line.rstrip(\"\\n\")\n          sent, tuples = line.split('===>')\n          sents.append(sent)\n          # tuples = tuples.replace(\"'\", \"\")\n          labels.append(tuples)\n\n  return sents, labels\n","metadata":{"id":"IoMSeVAEsRQu","execution":{"iopub.status.busy":"2023-12-10T11:39:44.280667Z","iopub.execute_input":"2023-12-10T11:39:44.280970Z","iopub.status.idle":"2023-12-10T11:39:44.296843Z","shell.execute_reply.started":"2023-12-10T11:39:44.280929Z","shell.execute_reply":"2023-12-10T11:39:44.295861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_max_length(inputs, tokenizer):\n    return max(len(tokenizer.encode(i)) for i in inputs)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:39:44.298770Z","iopub.execute_input":"2023-12-10T11:39:44.299389Z","iopub.status.idle":"2023-12-10T11:39:44.307306Z","shell.execute_reply.started":"2023-12-10T11:39:44.299356Z","shell.execute_reply":"2023-12-10T11:39:44.306630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, tokenizer, inputs=None, targets=None):\n        self.tokenizer = tokenizer\n        self.inputs, self.targets = inputs or [], targets or []\n        self.input_tensor_list, self.target_tensor_list = [], []\n\n        self.max_len = max_seq_length\n\n        self.input_tensor_list, self.target_tensor_list = self.encode(self.inputs, self.targets)\n\n\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        source_ids = self.input_tensor_list[idx][\"input_ids\"].squeeze()\n        target_ids = self.target_tensor_list[idx][\"input_ids\"].squeeze()\n\n        source_mask = self.input_tensor_list[idx][\"attention_mask\"].squeeze()\n        target_mask = self.target_tensor_list[idx][\"attention_mask\"].squeeze()\n\n        return {\"source_ids\": source_ids, \"source_mask\": source_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n\n    def encode(self, inputs=[], targets=[]):\n        input_tensor_list, target_tensor_list = [], []\n\n        for i in range(len(inputs)):\n            input_i = ' '.join(inputs[i]) if isinstance(inputs[i], list) else inputs[i]\n            target_i = ' '.join(targets[i]) if isinstance(targets[i], list) else targets[i]\n\n            tokenized_input = self.tokenizer.batch_encode_plus([input_i], max_length=self.max_len,padding='max_length', truncation=True, return_tensors=\"pt\")\n            tokenized_target = self.tokenizer.batch_encode_plus([target_i], max_length=self.max_len, padding='max_length', truncation=True, return_tensors=\"pt\")\n\n            input_tensor_list.append(tokenized_input)\n            target_tensor_list.append(tokenized_target)\n            \n        return input_tensor_list, target_tensor_list\n\ndef get_dataset(file_path, tokenizer, mode=\"train\"):\n    inputs, targets = read_data_file(file_path)\n    dataset = MyDataset(tokenizer, inputs=inputs, targets=targets)\n    return dataset\n\n\n","metadata":{"id":"91_OkLWpAJzv","execution":{"iopub.status.busy":"2023-12-10T11:39:44.308465Z","iopub.execute_input":"2023-12-10T11:39:44.308779Z","iopub.status.idle":"2023-12-10T11:39:44.321316Z","shell.execute_reply.started":"2023-12-10T11:39:44.308748Z","shell.execute_reply":"2023-12-10T11:39:44.320589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# SPECIAL_TOKENS = ['<sub>', '<obj>', '<asp>', '<pred>', '<lab>', '<unk>', 'COM', 'COM+', 'COM-', 'SUP', 'SUP+', 'SUP-', 'EQL', 'DIF', '(', ')']\n\n# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n# tokenizer.add_tokens(SPECIAL_TOKENS)\n# train_data = get_dataset(os.path.join(data_dir, 'test.txt'), tokenizer)\n\n# max_length = 0\n# max_seq = ''\n# for data in train_data:\n#     if torch.count_nonzero(data['target_ids']) > max_length:\n#         max_length = torch.count_nonzero(data['target_ids'])\n#         max_seq = tokenizer.convert_ids_to_tokens(data['target_ids'], skip_special_tokens=True) #tokenizer.decode(data['target_ids'])\n        \n# print(max_seq)\n\n# max_length = 0\n# max_seq = ''\n# for data in train_data:\n#     if torch.count_nonzero(data['source_ids']) > max_length:\n#         max_length = torch.count_nonzero(data['source_ids'])\n#         max_seq = tokenizer.decode(data['source_ids'], skip_special_tokens=True)\n        \n# print(max_seq)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T21:50:20.596491Z","iopub.execute_input":"2023-11-27T21:50:20.596749Z","iopub.status.idle":"2023-11-27T21:50:20.608504Z","shell.execute_reply.started":"2023-11-27T21:50:20.596726Z","shell.execute_reply":"2023-11-27T21:50:20.607700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Infer","metadata":{"id":"lFkarI1SB37k"}},{"cell_type":"code","source":"def calculate_inference_loss(model, tokenizer, input_text, true_sequences):\n    # Generate sequences\n    with torch.no_grad():\n        generated_sequences = model.generate(**inputs)\n\n    # Tokenize true sequences\n    true_inputs = tokenizer(true_sequences, return_tensors=\"pt\", truncation=True, padding=True)\n\n    # Forward pass through the model for true sequences\n    with torch.no_grad():\n        true_outputs = model(**true_inputs)\n\n    # Get logits from the output for true sequences\n    true_logits = true_outputs.logits\n\n    # Calculate cross-entropy loss\n    loss = torch.nn.functional.cross_entropy(true_logits, generated_sequences.view(-1))\n\n    return loss.item()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T10:10:21.926841Z","iopub.execute_input":"2023-12-05T10:10:21.927588Z","iopub.status.idle":"2023-12-05T10:10:21.933359Z","shell.execute_reply.started":"2023-12-05T10:10:21.927554Z","shell.execute_reply":"2023-12-05T10:10:21.932368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SPECIAL_TOKENS = ['<sub>', '<obj>', '<asp>', '<pred>', '<lab>', '[UNK]', 'COM', 'COM+', 'COM-', 'SUP', 'SUP+', 'SUP-', 'EQL', 'DIF', '(', ')', ';']\n\ndef prepare_constrained_vocab(name):\n    inputs, _ = read_data_file(os.path.join(data_dir, f\"{name}.txt\"))\n    constrained_vocab = set(\" \".join(inputs).split())\n    constrained_vocab.update(SPECIAL_TOKENS)\n    constrained_vocab = list(constrained_vocab)\n    return list(SPECIAL_TOKENS)\n    \n    \n    \nclass Prefix_fn_cls():\n    def __init__(self, tokenizer, name, input_enc_idxs):\n        self.input_enc_idxs=input_enc_idxs\n        self.tokenizer= tokenizer\n        self.constrained_vocab = prepare_constrained_vocab(name)\n        # only add special_tokens for extract process\n        self.special_ids = [element for l in self.tokenizer(self.constrained_vocab, add_special_tokens=False)['input_ids'] for element in l]\n        self.special_ids = list(set(self.special_ids))\n\n    def get(self, batch_id, previous_tokens):\n        inputs = list(set(self.input_enc_idxs[batch_id].tolist())) + self.special_ids\n        return inputs","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:43:05.348896Z","iopub.execute_input":"2023-12-10T11:43:05.349266Z","iopub.status.idle":"2023-12-10T11:43:05.358716Z","shell.execute_reply.started":"2023-12-10T11:43:05.349241Z","shell.execute_reply":"2023-12-10T11:43:05.357710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer(dataset, model, tokenizer, batch_size, keep_mask= False, name=\"eval\", constrained=False, **decode_dict):\n    data_loader = DataLoader(dataset, batch_size=batch_size, num_workers=4)\n\n    if keep_mask:\n        print(\"Keep mask: \", keep_mask)\n        unwanted_tokens = [tokenizer.eos_token, tokenizer.pad_token]\n        unwanted_ids = tokenizer.convert_tokens_to_ids(unwanted_tokens)\n\n        def filter_decode(ids):\n            ids = [i for i in ids if i not in unwanted_ids]\n            tokens = tokenizer.convert_ids_to_tokens(ids)\n            sentence = tokenizer.convert_tokens_to_string(tokens)\n            return sentence\n\n    inputs, outputs, targets = [], [], []    \n    average_loss = 0\n    \n    model.eval()\n    \n    if name != \"eval\":\n        with torch.no_grad():\n            for batch in tqdm(data_loader, disable=True):\n                if constrained:\n                    prefix_fn_obj = Prefix_fn_cls(tokenizer, name, batch['source_ids'].to(device))\n                    prefix_fn = lambda batch_id, sent: prefix_fn_obj.get(batch_id, sent)\n                else:\n                    prefix_fn = None\n                outs_dict = model.generate(input_ids = batch['source_ids'].to(device),\n                                           attention_mask = batch['source_mask'].to(device),\n                                           output_scores = True,\n                                           return_dict_in_generate = True,\n                                           max_length = max_seq_length,\n                                           prefix_allowed_tokens_fn = prefix_fn,\n                                           **decode_dict)\n\n                outs = outs_dict['sequences']\n\n                if keep_mask:\n                    input_ = [filter_decode(ids) for ids in batch['source_ids']]\n                    dec = [filter_decode(ids) for ids in outs]\n                    target = [filter_decode(ids) for ids in batch['target_ids']]\n                else:\n                    input_ = [tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['source_ids']]\n                    dec = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outs]\n                    target = [tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['target_ids']]\n\n                inputs.extend(input_)\n                outputs.extend(dec)\n                targets.extend(target)\n                \n    elif name ==\"eval\":\n        criterion = nn.CrossEntropyLoss()\n        total_loss = 0\n        num_batches = len(data_loader)\n        with torch.no_grad():\n            for batch in tqdm(data_loader, disable=True):\n                lm_labels = batch[\"target_ids\"]\n                lm_labels[lm_labels[:, :] == tokenizer.pad_token_id] = -100\n                outs = model(\n                    batch[\"source_ids\"].to(device),\n                    attention_mask = batch[\"source_mask\"].to(device),\n                    labels = lm_labels.to(device),\n                    decoder_attention_mask = batch[\"target_mask\"].to(device),\n                    decoder_input_ids = None,\n                )\n\n            loss = outs[0]\n            total_loss += loss.item()\n            \n        average_loss = total_loss/num_batches\n#         print(f\"Average Evaluation Loss: {average_loss}\")\n                \n   \n    with open(os.path.join(inference_dir, f\"{name}_output_{constrained}.txt\"), \"w\", encoding=\"utf-8\") as f:\n        for i, o in enumerate(outputs):\n            f.write(f\"{inputs[i]} ===> {o}\\n\")\n\n    \n    return average_loss, inputs, outputs, targets\n\n\n","metadata":{"id":"wl425SQ8AJzw","execution":{"iopub.status.busy":"2023-12-10T11:43:24.591004Z","iopub.execute_input":"2023-12-10T11:43:24.591320Z","iopub.status.idle":"2023-12-10T11:43:24.608160Z","shell.execute_reply.started":"2023-12-10T11:43:24.591296Z","shell.execute_reply":"2023-12-10T11:43:24.607245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## eval metrics","metadata":{"id":"9e8GruktCZW2"}},{"cell_type":"code","source":"import copy\nfrom sklearn.metrics import f1_score, precision_recall_fscore_support\nimport re\n\ndef extract_elements(input_string):\n    input_list = input_string.split(';')\n    pattern = re.compile(r'<sub>(.*?)<obj>(.*?)<asp>(.*?)<pred>(.*?)<lab>(.*?)$')\n    result=[]\n    for i in input_list:\n        i = i.strip()\n        match = re.match(pattern, i[1:-1].strip())\n        \n        if match:\n            items = match.groups()  \n            new_items = []\n            for i in range(len(items)):\n                new_items.append(items[i].strip())\n            result.append(new_items)\n        else:\n            result.append(None)\n        \n    return result\n\ndef compute_metrics(predicted_list, gold_list):\n    # Transpose the list of tuples to get a list of lists where each list corresponds to a position\n    predicted_positions = list(map(list, zip(*predicted_list)))\n    gold_positions = list(map(list, zip(*gold_list)))\n\n    precision_scores = []\n    recall_scores = []\n    micro_f1_scores = []\n    macro_f1_scores = []\n    f1_scores = []\n\n    # Iterate over each position\n    for predicted, gold in zip(predicted_positions, gold_positions):\n        # Compute micro-F1 for the position\n        micro_f1 = f1_score(predicted, gold, average='micro')\n        micro_f1_scores.append(micro_f1)\n\n        # Compute macro-F1 for the position\n        macro_f1 = f1_score(predicted, gold, average='macro')\n        macro_f1_scores.append(macro_f1)\n\n        # Compute F1-score for the position\n        p, r, f1, _ = precision_recall_fscore_support(predicted, gold, average=None)\n        f1_scores.append(f1[0])\n        precision_scores.append(p[0])\n        recall_scores.append(r[0])\n\n    return precision_scores, recall_scores, micro_f1_scores, macro_f1_scores, f1_scores\n\n\ndef eval(pred_tups, gold_tups, verbose=\"quite\", elem_dict=None):\n    assert len(pred_tups) == len(gold_tups)\n\n    elem_dict = elem_dict\n    all_labels, all_predictions, error_preds = [], [], []\n    for index in range(len(gold_tups)):\n        predict_list = extract_elements(pred_tups[index])\n        gold_list = extract_elements(gold_tups[index])\n        \n        if len(gold_list) > len(predict_list):\n            error_preds.append(f\"{index} Incomplete Prediction: {gold_tups[index]} ===> {pred_tups[index]}\")\n            \n        for i in range(len(predict_list)):\n            if  i >= len(gold_list):\n                error_preds.append(f\"{index} Adundant Prediction: {pred_tups[index]}\")\n            elif predict_list[i] is None or gold_list[i] is None or len(gold_list[i]) != len(predict_list[i]) or len(predict_list[i]) != 5:\n                error_preds.append(f\"{index}: {gold_tups[index]} ===> {pred_tups[index]}\")\n            else:\n                all_labels.append(gold_list[i])\n                all_predictions.append(predict_list[i])\n        \n        \n\n    precision_scores, recall_scores, micro_f1, macro_f1, f1_scores = compute_metrics(all_predictions, all_labels)\n\n    scores_dict = {}\n    for i, elem in enumerate(elem_dict):\n        scores_dict[elem] = {\"P\": precision_scores[i], \"R\": recall_scores[i], \"F1\": f1_scores[i], \"Marco - F1\": macro_f1[i], \"Micro - F1\": micro_f1[i]}\n\n    with open(os.path.join(inference_dir, 'error_prediction.txt'), 'w', encoding='utf-8') as fout:\n        for i, error in enumerate(error_preds):\n            fout.write(f\"{error}\\n\")\n\n    print(f\"The number of error predictions: {len(error_preds)}\")\n    if verbose != \"quiet\":\n        print(f\"Evaluation Result: {scores_dict}\")\n\n    return scores_dict\n","metadata":{"id":"ocaJlQz6AJzw","execution":{"iopub.status.busy":"2023-12-10T11:43:36.716045Z","iopub.execute_input":"2023-12-10T11:43:36.716671Z","iopub.status.idle":"2023-12-10T11:43:37.184708Z","shell.execute_reply.started":"2023-12-10T11:43:36.716638Z","shell.execute_reply":"2023-12-10T11:43:37.183828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## train","metadata":{"id":"qoucNYTbCb_X"}},{"cell_type":"code","source":"def train(model, tokenizer, train_data, val_data, epochs, lr, train_batch_size, eval_batch_size, acc_step=None, save_model=False, save_last=False, elem_dict= elem_dict, constrained=False ):\n    print(\"#\"*20+\" BEGIN TRAINING \"+ \"#\"*20)\n    no_decay =[\"bias\", \"LayerNorm.Weight\"]\n    optimizer_grouped_parameters = [\n        {\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": weight_decay, },\n        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0, },\n    ]\n    optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=adam_epsilon)\n\n    if acc_step is None:\n        acc_step = gradient_accumulation_steps\n        \n    train_loader = DataLoader(train_data, batch_size=train_batch_size, drop_last=True, shuffle=True)\n    t_total = (\n        (len(train_loader.dataset) // (train_batch_size * max(1, len(n_gpu))))\n        // acc_step\n        *float(epochs)\n    )\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps = t_total)\n    train_iterator = trange(int(epochs), dynamic_ncols=True, desc=\"Epoch\")\n    \n    train_losses, eval_losses = [], []\n    for n_epoch, _ in enumerate(train_iterator):\n        epoch_train_loss = 0.0\n        epoch_iterator = tqdm(train_loader, dynamic_ncols=True, desc=\"Iteration\", disable=True)\n\n        for step, batch in enumerate(epoch_iterator):\n            model.train()\n\n            lm_labels = batch[\"target_ids\"]\n            lm_labels[lm_labels[:, :] == tokenizer.pad_token_id] = -100\n            outputs = model(\n                batch[\"source_ids\"].to(device),\n                attention_mask = batch[\"source_mask\"].to(device),\n                labels = lm_labels.to(device),\n                decoder_attention_mask = batch[\"target_mask\"].to(device),\n                decoder_input_ids = None,\n            )\n\n            loss = outputs[0]\n            loss.backward()\n            epoch_train_loss += loss.item()\n\n            if (step + 1) % acc_step == 0:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                optimizer.step()\n                scheduler.step()\n                model.zero_grad()\n        \n#         eval_loss = 0.0\n        eval_loss, sents, predictions, golds = infer(val_data, model, tokenizer, batch_size=train_batch_size, name=\"eval\", constrained=constrained)\n        eval_losses.append(eval_loss)\n        \n#         for i in range(5):\n#           if i < len(predictions):\n#             print(f\"{sents[i]} ===> {predictions[i]}\")\n\n        # score_dict = eval(predictions, golds, verbose=\"info\", elem_dict= elem_dict)\n\n#         if save_model and n_epoch in range(num_train_epochs)[-save_last_k:]:\n#             save_dir = os.path.join(result_dir, f\"{model_checkpoint}_checkpoint-e{n_epoch}-constrained-{constrained}\")\n#             if not os.path.exists(save_dir):\n#                 os.makedirs(save_dir)\n\n#             model.save_pretrained(save_dir)\n#             tokenizer.save_pretrained(save_dir)\n\n#             print(f\"Save model checkpoint to {save_dir}\")\n        \n        train_losses.append(epoch_train_loss / len(epoch_iterator))\n        \n        print(f\"Epoch {n_epoch} - Average epoch train loss: {epoch_train_loss / len(epoch_iterator):.5f} lr: {scheduler.get_last_lr()}\")\n        print(f\"Average Evaluation Loss: {eval_loss:.5f}\")\n\n    if save_last:\n        save_dir = os.path.join(result_dir, f\"{model_checkpoint.split('/')[-1]}-e{n_epoch}-extract-tuple-constrained-model-{constrained}\")\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n\n        model.save_pretrained(save_dir)\n        tokenizer.save_pretrained(save_dir)\n\n        print(f\"Save model checkpoint to {save_dir}\")\n    \n    with open(os.path.join(inference_dir, \"train_losses.txt\"), 'w') as f:\n        for loss in train_losses:\n            f.write(f\"{loss}\\n\")\n    \n    with open(os.path.join(inference_dir, \"eval_losses.txt\"), 'w') as f:\n        for loss in eval_losses:\n            f.write(f\"{loss}\\n\")\n\n    print(\"#\"*20+\" FINISH TRAINING \"+ \"#\"*20)\n","metadata":{"id":"YehjeObuAJzx","execution":{"iopub.status.busy":"2023-12-10T11:43:44.454973Z","iopub.execute_input":"2023-12-10T11:43:44.455819Z","iopub.status.idle":"2023-12-10T11:43:44.474817Z","shell.execute_reply.started":"2023-12-10T11:43:44.455781Z","shell.execute_reply":"2023-12-10T11:43:44.473924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run","metadata":{"id":"XvhftMJLCeoV"}},{"cell_type":"code","source":"# do_train = True\n# do_test = True\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\ndef main(do_train, do_test, test_label, constrained=False):\n    if do_train:\n        tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n        tokenizer.add_tokens(SPECIAL_TOKENS)\n        \n        train_inputs, train_labels = read_data_file(os.path.join(data_dir, \"train.txt\"))\n        train_max_length = get_max_length(train_labels, tokenizer)\n        eval_inputs, eval_labels = read_data_file(os.path.join(data_dir, \"dev.txt\"))\n        eval_max_length = get_max_length(eval_labels, tokenizer)\n    #     eval_max_length = 0\n\n        train_data = get_dataset(os.path.join(data_dir, \"train.txt\"), tokenizer=tokenizer)\n#         eval_data = []\n        eval_data = get_dataset(os.path.join(data_dir, \"dev.txt\"), tokenizer=tokenizer)\n\n        model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n        model.resize_token_embeddings(len(tokenizer))\n        model.to(device)\n\n        print(f\"Train: {len(train_data)}, Eval: {len(eval_data)}, Model: {model_checkpoint}\")\n        print(f\"Train Label Max Length : {train_max_length}\\nEval Label Max Length: {eval_max_length}\")\n\n        print(\"*\"*20+\" Training \"+\"*\"*20)\n        train(model, tokenizer, train_data, eval_data, epochs=num_train_epochs, lr=lr, train_batch_size=train_batch_size, eval_batch_size=eval_batch_size, save_model=True, save_last=True, elem_dict=elem_dict, constrained=constrained)\n\n    \n    \n    if do_test:\n        print(\"*\"*20+\" TESTING \"+\"*\"*20)\n        all_checkpoints = []\n        saved_model_dir = result_dir\n\n        for f in os.listdir(saved_model_dir):\n            file_name = os.path.join(saved_model_dir, f)\n            if 'constrained-model' in f and model_checkpoint.split('/')[-1] in f:\n                all_checkpoints.append(file_name)\n        \n    \n        test_inputs, _ = read_data_file(os.path.join(data_dir, \"test.txt\"))\n        print(f\"Test: {len(test_inputs)}\")\n\n        best_f1, best_checkpoint, best_epoch = -999999.0, None, None\n        best_score_dict, best_pred_dict = None, None\n        all_epochs = []\n\n    #     del model\n#         print(\"*\"*20+\" Testing \"+\"*\"*20)\n\n        for checkpoint in all_checkpoints:\n            model_name = checkpoint.split('/')[-1]\n#             epoch = checkpoint.split('-')[-1][1:]\n#             all_epochs.append(epoch)\n            print(f\"Load model from checkpoint {checkpoint}\")\n\n            model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n            tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n              \n            test_data = get_dataset(os.path.join(data_dir, \"test.txt\"), tokenizer=tokenizer)\n              \n            model.to(device)\n\n            _, sents, predictions, golds = infer(test_data, model, tokenizer, batch_size=train_batch_size, name=\"test\", constrained=constrained)\n\n            for i in range(5):\n              if i < len(predictions):\n                print(f\"{sents[i]} ===> {predictions[i]}\")\n              \n            if test_label:\n                score_dict = eval(predictions, golds, verbose=\"info\", elem_dict=elem_dict)\n\n            with open(f\"{inference_dir}/test-{model_name}.txt\", 'w', encoding=\"utf-8\") as fout:\n                for i, s in enumerate(sents):\n                    fout.write(f\"{s} ===> {predictions[i]}\\n\")\n","metadata":{"id":"Rg-ag4orAJzx","execution":{"iopub.status.busy":"2023-12-10T11:43:53.480103Z","iopub.execute_input":"2023-12-10T11:43:53.481009Z","iopub.status.idle":"2023-12-10T11:43:53.502025Z","shell.execute_reply.started":"2023-12-10T11:43:53.480967Z","shell.execute_reply":"2023-12-10T11:43:53.501092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main(do_train = True, do_test = True, test_label = False, constrained=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:43:56.317161Z","iopub.execute_input":"2023-12-10T11:43:56.317515Z","iopub.status.idle":"2023-12-10T13:25:09.277298Z","shell.execute_reply.started":"2023-12-10T11:43:56.317488Z","shell.execute_reply":"2023-12-10T13:25:09.276341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -rf /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:08:59.790862Z","iopub.execute_input":"2023-11-27T23:08:59.791549Z","iopub.status.idle":"2023-11-27T23:08:59.796222Z","shell.execute_reply.started":"2023-11-27T23:08:59.791509Z","shell.execute_reply":"2023-11-27T23:08:59.795311Z"},"trusted":true},"execution_count":null,"outputs":[]}]}